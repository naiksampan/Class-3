{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1629bce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated /Users/nebula/Desktop/Projects/Sanket/Data/non surgical 212 zip/annotations/person_keypoints_default.json â†’ Saved to /Users/nebula/Desktop/Projects/Sanket/Data/non surgical 212 zip/annotations/person_keypoints_updated.json (category_id = 0)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def update_category_ids(json_path, output_path, new_category_id):\n",
    "    \"\"\"\n",
    "    Updates category_id in both categories[] and annotations[] for a COCO-style JSON file.\n",
    "    Args:\n",
    "        json_path (str): Input JSON annotation file path.\n",
    "        output_path (str): Output JSON file path to save the updated version.\n",
    "        new_category_id (int): New category ID (0 or 1).\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Update category ids in \"categories\"\n",
    "    for cat in data.get(\"categories\", []):\n",
    "        cat[\"id\"] = new_category_id\n",
    "\n",
    "    # Update category ids in \"annotations\"\n",
    "    for ann in data.get(\"annotations\", []):\n",
    "        ann[\"category_id\"] = new_category_id\n",
    "\n",
    "    # Save updated JSON\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    print(f\"âœ… Updated {json_path} â†’ Saved to {output_path} (category_id = {new_category_id})\")\n",
    "\n",
    "\n",
    "# ---- Example Usage ----\n",
    "# Non-surgical file â†’ category_id = 0\n",
    "update_category_ids(\"/Users/nebula/Desktop/Projects/Sanket/Data/non surgical 212 zip/annotations/person_keypoints_default.json\", \"/Users/nebula/Desktop/Projects/Sanket/Data/non surgical 212 zip/annotations/person_keypoints_updated.json\", 0)\n",
    "\n",
    "# Surgical file â†’ category_id = 1\n",
    "# update_category_ids(\"surgical.json\", \"surgical_updated.json\", 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cba57606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def merge_annotations_from_folder(\n",
    "    original_json_path,\n",
    "    new_image_dir,\n",
    "    output_json_path\n",
    "):\n",
    "    \"\"\"\n",
    "    Merge COCO-style annotations from original JSON into a target JSON,\n",
    "    keeping only images that exist in new_image_dir and preserving category IDs.\n",
    "    \"\"\"\n",
    "    # Load source JSON\n",
    "    with open(original_json_path, 'r') as f:\n",
    "        orig_data = json.load(f)\n",
    "\n",
    "    # Load or initialize destination JSON\n",
    "    if os.path.exists(output_json_path):\n",
    "        print(f\"ðŸ“‚ Loading existing file: {output_json_path}\")\n",
    "        with open(output_json_path, 'r') as f:\n",
    "            merged_data = json.load(f)\n",
    "    else:\n",
    "        print(f\"ðŸ†• Creating new file: {output_json_path}\")\n",
    "        merged_data = {\n",
    "            \"licenses\": orig_data.get(\"licenses\", []),\n",
    "            \"info\": orig_data.get(\"info\", {}),\n",
    "            \"categories\": [],\n",
    "            \"images\": [],\n",
    "            \"annotations\": []\n",
    "        }\n",
    "\n",
    "    # âœ… Merge unique categories (avoid duplicates)\n",
    "    existing_cat_names = {cat[\"name\"] for cat in merged_data.get(\"categories\", [])}\n",
    "    for cat in orig_data.get(\"categories\", []):\n",
    "        if cat[\"name\"] not in existing_cat_names:\n",
    "            merged_data[\"categories\"].append(cat)\n",
    "            existing_cat_names.add(cat[\"name\"])\n",
    "\n",
    "    # Collect existing image filenames\n",
    "    existing_filenames = {os.path.basename(img[\"file_name\"]).lower() for img in merged_data[\"images\"]}\n",
    "\n",
    "    # List available images in folder\n",
    "    available_images = {\n",
    "        f.lower() for f in os.listdir(new_image_dir)\n",
    "        if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "    }\n",
    "\n",
    "    # Track next IDs\n",
    "    next_image_id = max([img[\"id\"] for img in merged_data[\"images\"]], default=0) + 1\n",
    "    next_ann_id = max([ann[\"id\"] for ann in merged_data[\"annotations\"]], default=0) + 1\n",
    "\n",
    "    image_id_map = {}\n",
    "\n",
    "    # --- Copy matching images ---\n",
    "    for img in tqdm(orig_data[\"images\"], desc=\"Processing new images\"):\n",
    "        base_name = os.path.basename(img[\"file_name\"]).lower()\n",
    "        if base_name in available_images and base_name not in existing_filenames:\n",
    "            new_img = img.copy()\n",
    "            new_img[\"file_name\"] = os.path.join(os.path.basename(new_image_dir), os.path.basename(img[\"file_name\"]))\n",
    "            new_img[\"id\"] = next_image_id\n",
    "            image_id_map[img[\"id\"]] = next_image_id\n",
    "            merged_data[\"images\"].append(new_img)\n",
    "\n",
    "            existing_filenames.add(base_name)\n",
    "            next_image_id += 1\n",
    "\n",
    "    # --- Copy matching annotations ---\n",
    "    for ann in tqdm(orig_data[\"annotations\"], desc=\"Processing new annotations\"):\n",
    "        old_img_id = ann[\"image_id\"]\n",
    "        if old_img_id in image_id_map:\n",
    "            new_ann = ann.copy()\n",
    "            new_ann[\"image_id\"] = image_id_map[old_img_id]\n",
    "            new_ann[\"id\"] = next_ann_id\n",
    "\n",
    "            # âœ… Keep category_id unchanged\n",
    "            # (e.g., 0 for non-surgical, 1 for surgical)\n",
    "            merged_data[\"annotations\"].append(new_ann)\n",
    "            next_ann_id += 1\n",
    "\n",
    "    # Save final JSON\n",
    "    os.makedirs(os.path.dirname(output_json_path), exist_ok=True)\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(merged_data, f, indent=4)\n",
    "\n",
    "    print(f\"\\nâœ… Merged and saved: {output_json_path}\")\n",
    "    print(f\"ðŸ“Š Total images: {len(merged_data['images'])}\")\n",
    "    print(f\"ðŸ“Š Total annotations: {len(merged_data['annotations'])}\")\n",
    "    print(f\"ðŸ“Š Categories: {[cat['name'] for cat in merged_data['categories']]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "988c72ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ†• Creating new file: /Users/nebula/Desktop/Projects/Sanket/Data/Recent_data/val/images/annotation/n-person_keypoints_default.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing new images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [00:00<00:00, 245368.51it/s]\n",
      "Processing new annotations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212/212 [00:00<00:00, 410902.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Merged and saved: /Users/nebula/Desktop/Projects/Sanket/Data/Recent_data/val/images/annotation/n-person_keypoints_default.json\n",
      "ðŸ“Š Total images: 44\n",
      "ðŸ“Š Total annotations: 44\n",
      "ðŸ“Š Categories: ['surgical', 'non surgical']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Example usage ---\n",
    "merge_annotations_from_folder(\n",
    "    original_json_path=\"/Users/nebula/Desktop/Projects/Sanket/Data/non surgical 212 zip/annotations/person_keypoints_updated.json\",\n",
    "    new_image_dir=\"/Users/nebula/Desktop/Projects/Sanket/Data/Recent_data/val/images\",\n",
    "    output_json_path=\"/Users/nebula/Desktop/Projects/Sanket/Data/Recent_data/val/images/annotation/n-person_keypoints_default.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b260fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading existing file: /Users/nebula/Desktop/Projects/Sanket/Data/Recent_data/val/images/annotation/n-person_keypoints_default.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing new images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:00<00:00, 288722.86it/s]\n",
      "Processing new annotations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201/201 [00:00<00:00, 443713.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Merged and saved: /Users/nebula/Desktop/Projects/Sanket/Data/Recent_data/val/images/annotation/n-person_keypoints_default.json\n",
      "ðŸ“Š Total images: 84\n",
      "ðŸ“Š Total annotations: 82\n",
      "ðŸ“Š Categories: ['surgical', 'non surgical']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "merge_annotations_from_folder(\n",
    "    original_json_path=\"/Users/nebula/Desktop/Projects/Sanket/Data/surgical 204/annotations/person_keypoints_updated.json\",\n",
    "    new_image_dir=\"/Users/nebula/Desktop/Projects/Sanket/Data/Recent_data/val/images\",\n",
    "    output_json_path=\"/Users/nebula/Desktop/Projects/Sanket/Data/Recent_data/val/images/annotation/n-person_keypoints_default.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f870d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fixed image paths in: /Users/nebula/Desktop/Projects/Sanket/Data/Recent_data/train/images/annotation/n-person_keypoints_default.json\n",
      "âœ… Fixed image paths in: /Users/nebula/Desktop/Projects/Sanket/Data/Recent_data/val/images/annotation/n-person_keypoints_default.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def fix_image_paths(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for img in data['images']:\n",
    "        # remove \"train/\" or \"validation/\" or \"val/\" prefixes safely\n",
    "        img['file_name'] = os.path.basename(img['file_name'])\n",
    "\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    print(f\"âœ… Fixed image paths in: {json_path}\")\n",
    "\n",
    "# Run for both splits\n",
    "fix_image_paths(\"/Users/nebula/Desktop/Projects/Sanket/Data/Recent_data/train/images/annotation/n-person_keypoints_default.json\")\n",
    "fix_image_paths(\"/Users/nebula/Desktop/Projects/Sanket/Data/Recent_data/val/images/annotation/n-person_keypoints_default.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffec5b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
